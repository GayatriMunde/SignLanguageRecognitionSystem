{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDAI.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZ/T3IQ/C92jrQ/uzgRPPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GayatriMunde/SignLanguageRecognitionSystem/blob/main/temp_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP4f6qLEyhgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a0878e-3148-42bb-bd71-d5e878d03241"
      },
      "source": [
        "!git clone https://github.com/GayatriMunde/TempData.git"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TempData' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZZCn_qLLJwa"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras import optimizers"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wEeMeSwLYl8"
      },
      "source": [
        "classifier = Sequential()"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1kFgFxJNJrk"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oDw_FH4NQYu",
        "outputId": "ceca9fef-5f33-4bca-c3da-8910741600b5"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/TempData/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2719 images belonging to 36 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypgj7lKbNaWF",
        "outputId": "18838526-e657-4fd9-84f0-3353f57d39c4"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/TempData/test',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1082 images belonging to 36 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hsgScYZLbIn"
      },
      "source": [
        "classifier.add(Convolution2D(32, 3,  3, input_shape = (64, 64, 3), activation = 'relu', padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2), padding='same'))\n",
        "classifier.add(Convolution2D(32, 3,  3, activation = 'relu', padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2), padding='same'))\n",
        "classifier.add(Convolution2D(64, 3,  3, activation = 'relu', padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2), padding='same'))\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GktpPPo-Q5U0",
        "outputId": "e209ca23-7a31-4d05-df59-af8ad5444b5e"
      },
      "source": [
        " from tensorflow.keras import optimizers\n",
        "\n",
        "classifier.add(Dense(256, activation = 'relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(36, activation = 'softmax'))\n",
        "\n",
        "#Compiling The CNN\n",
        "classifier.compile(\n",
        "              optimizer = optimizers.SGD(lr = 0.01),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWxUCJsLMkQq"
      },
      "source": [
        "classifier.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17qA0tpOPto1",
        "outputId": "ea00f823-4521-4103-aa3e-34754431325b"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 22, 22, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 11, 11, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 4, 4, 32)          9248      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 2, 2, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 1, 1, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               16640     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 36)                9252      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,532\n",
            "Trainable params: 54,532\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq11a7yXPxIv"
      },
      "source": [
        "train_total = 2719\n",
        "valid_total = 1082\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQDjFcjRP3N-",
        "outputId": "f0f0f1f7-abba-4323-9fcc-5154e0d76987"
      },
      "source": [
        "history = classifier.fit_generator(\n",
        "    generator=training_set,\n",
        "    steps_per_epoch=(train_total + BATCH_SIZE - 1) // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_set,\n",
        "    validation_steps=(valid_total + BATCH_SIZE - 1) // BATCH_SIZE,\n",
        ")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\r 1/85 [..............................] - ETA: 6s - loss: 0.6070 - accuracy: 0.8438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 7s 82ms/step - loss: 0.4078 - accuracy: 0.8783 - val_loss: 7.0602 - val_accuracy: 0.3244\n",
            "Epoch 2/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.3447 - accuracy: 0.9000 - val_loss: 6.9942 - val_accuracy: 0.3253\n",
            "Epoch 3/25\n",
            "85/85 [==============================] - 7s 81ms/step - loss: 0.2988 - accuracy: 0.9092 - val_loss: 6.9153 - val_accuracy: 0.3170\n",
            "Epoch 4/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.2703 - accuracy: 0.9187 - val_loss: 7.6068 - val_accuracy: 0.3281\n",
            "Epoch 5/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.2505 - accuracy: 0.9268 - val_loss: 7.7379 - val_accuracy: 0.3059\n",
            "Epoch 6/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.2248 - accuracy: 0.9301 - val_loss: 7.8135 - val_accuracy: 0.3253\n",
            "Epoch 7/25\n",
            "85/85 [==============================] - 7s 81ms/step - loss: 0.2028 - accuracy: 0.9408 - val_loss: 8.0254 - val_accuracy: 0.3262\n",
            "Epoch 8/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1833 - accuracy: 0.9408 - val_loss: 8.0976 - val_accuracy: 0.3189\n",
            "Epoch 9/25\n",
            "85/85 [==============================] - 7s 81ms/step - loss: 0.1634 - accuracy: 0.9537 - val_loss: 8.3363 - val_accuracy: 0.3327\n",
            "Epoch 10/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1569 - accuracy: 0.9544 - val_loss: 8.8334 - val_accuracy: 0.3373\n",
            "Epoch 11/25\n",
            "85/85 [==============================] - 7s 87ms/step - loss: 0.1531 - accuracy: 0.9515 - val_loss: 8.1753 - val_accuracy: 0.3318\n",
            "Epoch 12/25\n",
            "85/85 [==============================] - 7s 87ms/step - loss: 0.1492 - accuracy: 0.9555 - val_loss: 8.4980 - val_accuracy: 0.3226\n",
            "Epoch 13/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1313 - accuracy: 0.9584 - val_loss: 8.9853 - val_accuracy: 0.3530\n",
            "Epoch 14/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1246 - accuracy: 0.9621 - val_loss: 8.4640 - val_accuracy: 0.3503\n",
            "Epoch 15/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1290 - accuracy: 0.9548 - val_loss: 8.8595 - val_accuracy: 0.3272\n",
            "Epoch 16/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1298 - accuracy: 0.9584 - val_loss: 8.8136 - val_accuracy: 0.3392\n",
            "Epoch 17/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1215 - accuracy: 0.9643 - val_loss: 9.0994 - val_accuracy: 0.3604\n",
            "Epoch 18/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1064 - accuracy: 0.9691 - val_loss: 9.0469 - val_accuracy: 0.3558\n",
            "Epoch 19/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.0985 - accuracy: 0.9676 - val_loss: 8.9867 - val_accuracy: 0.3466\n",
            "Epoch 20/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.0850 - accuracy: 0.9754 - val_loss: 9.4498 - val_accuracy: 0.3447\n",
            "Epoch 21/25\n",
            "85/85 [==============================] - 7s 81ms/step - loss: 0.1065 - accuracy: 0.9676 - val_loss: 9.2727 - val_accuracy: 0.3355\n",
            "Epoch 22/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1170 - accuracy: 0.9588 - val_loss: 8.8498 - val_accuracy: 0.3364\n",
            "Epoch 23/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.1044 - accuracy: 0.9684 - val_loss: 8.7848 - val_accuracy: 0.3762\n",
            "Epoch 24/25\n",
            "85/85 [==============================] - 7s 82ms/step - loss: 0.0880 - accuracy: 0.9757 - val_loss: 9.1893 - val_accuracy: 0.3410\n",
            "Epoch 25/25\n",
            "85/85 [==============================] - 7s 81ms/step - loss: 0.0851 - accuracy: 0.9739 - val_loss: 9.1972 - val_accuracy: 0.3835\n"
          ]
        }
      ]
    }
  ]
}